{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# imports","metadata":{}},{"cell_type":"code","source":"import os\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\nimport xml.etree.ElementTree as ET\n\nimport numpy as np\nimport pandas as pd\n\nfrom skimage.io import imread\nfrom skimage.transform import resize\nfrom PIL import Image\nfrom imgaug import augmenters as iaa\n\nfrom sklearn.model_selection import train_test_split\n\nfrom keras.models import *\nfrom keras.layers import *\nfrom keras.optimizers import *\nfrom keras.utils import *\nfrom keras.callbacks import *\n\nfrom keras.applications.densenet import DenseNet121, preprocess_input","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-01T00:16:11.621087Z","iopub.execute_input":"2022-02-01T00:16:11.621691Z","iopub.status.idle":"2022-02-01T00:16:14.505808Z","shell.execute_reply.started":"2022-02-01T00:16:11.621637Z","shell.execute_reply":"2022-02-01T00:16:14.505148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# how many breeds and pictures we have","metadata":{}},{"cell_type":"code","source":"breed_list = os.listdir(\"../input/dogsdatasetsmall/stanford-dogs-dataset/images/Images/\")\n\nnum_classes = len(breed_list)\nprint(\"{} breeds\".format(num_classes))\n\nn_total_images = 0\nfor breed in breed_list:\n    n_total_images += len(os.listdir(\"../input/dogsdatasetsmall/stanford-dogs-dataset/images/Images/{}\".format(breed)))\nprint(\"{} images\".format(n_total_images))","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.status.busy":"2022-02-01T00:16:16.940449Z","iopub.execute_input":"2022-02-01T00:16:16.940786Z","iopub.status.idle":"2022-02-01T00:16:17.249975Z","shell.execute_reply.started":"2022-02-01T00:16:16.940721Z","shell.execute_reply":"2022-02-01T00:16:17.249054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# label strings and numbers mapping","metadata":{}},{"cell_type":"code","source":"label_maps = {}\nlabel_maps_rev = {}\nfor i, v in enumerate(breed_list):\n    label_maps.update({v: i})\n    label_maps_rev.update({i : v})","metadata":{"execution":{"iopub.status.busy":"2022-02-01T00:16:18.879201Z","iopub.execute_input":"2022-02-01T00:16:18.879514Z","iopub.status.idle":"2022-02-01T00:16:18.884354Z","shell.execute_reply.started":"2022-02-01T00:16:18.879454Z","shell.execute_reply":"2022-02-01T00:16:18.883461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# show some pictures","metadata":{}},{"cell_type":"code","source":"def show_dir_images(breed, n_to_show):\n    plt.figure(figsize=(16,16))\n    img_dir = \"../input/dogsdatasetsmall/stanford-dogs-dataset/images/Images/{}/\".format(breed)\n    images = os.listdir(img_dir)[:n_to_show]\n    for i in range(n_to_show):\n        img = mpimg.imread(img_dir + images[i])\n        plt.subplot(n_to_show/4+1, 4, i+1)\n        plt.imshow(img)\n        plt.axis('off')","metadata":{"execution":{"iopub.status.busy":"2022-02-01T00:16:20.695326Z","iopub.execute_input":"2022-02-01T00:16:20.695941Z","iopub.status.idle":"2022-02-01T00:16:20.701832Z","shell.execute_reply.started":"2022-02-01T00:16:20.695894Z","shell.execute_reply":"2022-02-01T00:16:20.70075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(breed_list[0])\nshow_dir_images(breed_list[0], 16)","metadata":{"execution":{"iopub.status.busy":"2022-02-01T00:16:22.035262Z","iopub.execute_input":"2022-02-01T00:16:22.035876Z","iopub.status.idle":"2022-02-01T00:16:23.821049Z","shell.execute_reply.started":"2022-02-01T00:16:22.035817Z","shell.execute_reply":"2022-02-01T00:16:23.820437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# crop and save pictures","metadata":{}},{"cell_type":"code","source":"%%time\n\n# copy from https://www.kaggle.com/gabrielloye/dogs-inception-pytorch-implementation\n# reduce the background noise\n\nos.mkdir('data')\nfor breed in breed_list:\n    os.mkdir('data/' + breed)\nprint('Created {} folders to store cropped images of the different breeds.'.format(len(os.listdir('data'))))\n\nfor breed in os.listdir('data'):\n    for file in os.listdir('../input/dogsdatasetsmall/stanford-dogs-dataset/annotations/Annotation/{}'.format(breed)):\n        img = Image.open('../input/dogsdatasetsmall/stanford-dogs-dataset/images/Images/{}/{}.jpg'.format(breed, file))\n        tree = ET.parse('../input/dogsdatasetsmall/stanford-dogs-dataset/annotations/Annotation/{}/{}'.format(breed, file))\n        xmin = int(tree.getroot().findall('object')[0].find('bndbox').find('xmin').text)\n        xmax = int(tree.getroot().findall('object')[0].find('bndbox').find('xmax').text)\n        ymin = int(tree.getroot().findall('object')[0].find('bndbox').find('ymin').text)\n        ymax = int(tree.getroot().findall('object')[0].find('bndbox').find('ymax').text)\n        img = img.crop((xmin, ymin, xmax, ymax))\n        img = img.convert('RGB')\n        img = img.resize((224, 224))\n        img.save('data/' + breed + '/' + file + '.jpg')","metadata":{"execution":{"iopub.status.busy":"2022-02-01T00:16:30.027469Z","iopub.execute_input":"2022-02-01T00:16:30.028129Z","iopub.status.idle":"2022-02-01T00:16:53.032466Z","shell.execute_reply.started":"2022-02-01T00:16:30.028075Z","shell.execute_reply":"2022-02-01T00:16:53.03188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# prepare X and y","metadata":{}},{"cell_type":"code","source":"def paths_and_labels():\n    paths = list()\n    labels = list()\n    targets = list()\n    for breed in breed_list:\n        base_name = \"./data/{}/\".format(breed)\n        for img_name in os.listdir(base_name):\n            paths.append(base_name + img_name)\n            labels.append(breed)\n            targets.append(label_maps[breed])\n    return paths, labels, targets\n\npaths, labels, targets = paths_and_labels()\n\nassert len(paths) == len(labels)\nassert len(paths) == len(targets)\n\ntargets = np_utils.to_categorical(targets, num_classes=num_classes)\nprint(\"done\")","metadata":{"execution":{"iopub.status.busy":"2022-02-01T00:16:53.033444Z","iopub.execute_input":"2022-02-01T00:16:53.033886Z","iopub.status.idle":"2022-02-01T00:16:53.044922Z","shell.execute_reply.started":"2022-02-01T00:16:53.03381Z","shell.execute_reply":"2022-02-01T00:16:53.044073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# image generator with augment","metadata":{}},{"cell_type":"code","source":"batch_size = 64\n\nclass ImageGenerator(Sequence):\n    \n    def __init__(self, paths, targets, batch_size, shape, augment=False):\n        self.paths = paths\n        self.targets = targets\n        self.batch_size = batch_size\n        self.shape = shape\n        self.augment = augment\n        \n    def __len__(self):\n        return int(np.ceil(len(self.paths) / float(self.batch_size)))\n    \n    def __getitem__(self, idx):\n        batch_paths = self.paths[idx * self.batch_size : (idx + 1) * self.batch_size]\n        x = np.zeros((len(batch_paths), self.shape[0], self.shape[1], self.shape[2]), dtype=np.float32)\n        y = np.zeros((self.batch_size, num_classes, 1))\n        for i, path in enumerate(batch_paths):\n            x[i] = self.__load_image(path)\n        y = self.targets[idx * self.batch_size : (idx + 1) * self.batch_size]\n        return x, y\n    \n    def __iter__(self):\n        for item in (self[i] for i in range(len(self))):\n            yield item\n            \n    def __load_image(self, path):\n        image = imread(path)\n        image = preprocess_input(image)\n        if self.augment:\n            seq = iaa.Sequential([\n                iaa.OneOf([\n                    iaa.Fliplr(0.5),\n                    iaa.Flipud(0.5),\n                    iaa.CropAndPad(percent=(-0.25, 0.25)),\n                    iaa.Crop(percent=(0, 0.1)),\n                    iaa.Sometimes(0.5,\n                        iaa.GaussianBlur(sigma=(0, 0.5))\n                    ),\n                    iaa.Affine(\n                        scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n                        translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n                        rotate=(-180, 180),\n                        shear=(-8, 8)\n                    )\n                ])\n            ], random_order=True)\n            image = seq.augment_image(image)\n        return image","metadata":{"execution":{"iopub.status.busy":"2022-02-01T00:16:53.046252Z","iopub.execute_input":"2022-02-01T00:16:53.046512Z","iopub.status.idle":"2022-02-01T00:16:53.0671Z","shell.execute_reply.started":"2022-02-01T00:16:53.046454Z","shell.execute_reply":"2022-02-01T00:16:53.066196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# train test split","metadata":{}},{"cell_type":"code","source":"train_paths, val_paths, train_targets, val_targets = train_test_split(paths, \n                                                  targets,\n                                                  test_size=0.15, \n                                                  random_state=1029)\n\ntrain_gen = ImageGenerator(train_paths, train_targets, batch_size=32, shape=(224,224,3), augment=True)\nval_gen = ImageGenerator(val_paths, val_targets, batch_size=32, shape=(224,224,3), augment=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-01T00:16:53.068421Z","iopub.execute_input":"2022-02-01T00:16:53.068727Z","iopub.status.idle":"2022-02-01T00:16:53.084382Z","shell.execute_reply.started":"2022-02-01T00:16:53.06868Z","shell.execute_reply":"2022-02-01T00:16:53.083545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# keras pretrain densenet121 model","metadata":{}},{"cell_type":"code","source":"inp = Input((224, 224, 3))\nbackbone = DenseNet121(input_tensor=inp,\n                       weights=\"../input/densenet-keras/DenseNet-BC-121-32-no-top.h5\",\n                       include_top=False)\nx = backbone.output\nx = GlobalAveragePooling2D()(x)\nx = Dense(1024, activation=\"relu\")(x)\nx = Dropout(0.5)(x)\nx = Dense(512, activation=\"relu\")(x)\nx = Dropout(0.5)(x)\noutp = Dense(num_classes, activation=\"softmax\")(x)\n\nmodel = Model(inp, outp)","metadata":{"execution":{"iopub.status.busy":"2022-02-01T00:17:01.573614Z","iopub.execute_input":"2022-02-01T00:17:01.574279Z","iopub.status.idle":"2022-02-01T00:17:24.311989Z","shell.execute_reply.started":"2022-02-01T00:17:01.574227Z","shell.execute_reply":"2022-02-01T00:17:24.311014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# only train our last 6 layers","metadata":{}},{"cell_type":"code","source":"for layer in model.layers[:-6]:\n    layer.trainable = False","metadata":{"execution":{"iopub.status.busy":"2022-02-01T00:17:24.313529Z","iopub.execute_input":"2022-02-01T00:17:24.313796Z","iopub.status.idle":"2022-02-01T00:17:24.318388Z","shell.execute_reply.started":"2022-02-01T00:17:24.313746Z","shell.execute_reply":"2022-02-01T00:17:24.317558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer=\"adam\",\n              loss=\"categorical_crossentropy\",\n              metrics=[\"acc\"])","metadata":{"execution":{"iopub.status.busy":"2022-02-01T00:17:24.319824Z","iopub.execute_input":"2022-02-01T00:17:24.320096Z","iopub.status.idle":"2022-02-01T00:17:24.374703Z","shell.execute_reply.started":"2022-02-01T00:17:24.320047Z","shell.execute_reply":"2022-02-01T00:17:24.373986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit_generator(generator=train_gen, \n                              steps_per_epoch=len(train_gen), \n                              validation_data=val_gen, \n                              validation_steps=len(val_gen),\n                              epochs=5)","metadata":{"execution":{"iopub.status.busy":"2022-02-01T00:17:24.376007Z","iopub.execute_input":"2022-02-01T00:17:24.37652Z","iopub.status.idle":"2022-02-01T00:51:24.421641Z","shell.execute_reply.started":"2022-02-01T00:17:24.376479Z","shell.execute_reply":"2022-02-01T00:51:24.420469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (6,6)\n\nacc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(acc) + 1)\n\nplt.title('Training and validation accuracy')\nplt.plot(epochs, acc, 'red', label='Training acc')\nplt.plot(epochs, val_acc, 'blue', label='Validation acc')\nplt.legend()\n\nplt.figure()\nplt.title('Training and validation loss')\nplt.plot(epochs, loss, 'red', label='Training loss')\nplt.plot(epochs, val_loss, 'blue', label='Validation loss')\n\nplt.legend()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-01T00:51:31.377602Z","iopub.execute_input":"2022-02-01T00:51:31.377977Z","iopub.status.idle":"2022-02-01T00:51:31.996994Z","shell.execute_reply.started":"2022-02-01T00:51:31.377907Z","shell.execute_reply":"2022-02-01T00:51:31.995606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# now train all layers","metadata":{}},{"cell_type":"code","source":"for layer in model.layers[:]:\n    layer.trainable = True","metadata":{"execution":{"iopub.status.busy":"2022-02-01T00:51:57.230082Z","iopub.execute_input":"2022-02-01T00:51:57.230371Z","iopub.status.idle":"2022-02-01T00:51:57.234339Z","shell.execute_reply.started":"2022-02-01T00:51:57.230328Z","shell.execute_reply":"2022-02-01T00:51:57.233683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# a check point callback to save our best weights\ncheckpoint = ModelCheckpoint('dog_breed_classifier_model.h5', \n                             monitor='val_acc', \n                             verbose=1, \n                             save_best_only=True, \n                             mode='max', \n                             save_weights_only=True)\n\n# a reducing lr callback to reduce lr when val_loss doesn't increase\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n                                   patience=1, verbose=1, mode='min',\n                                   min_delta=0.0001, cooldown=2, min_lr=1e-7)\n\n# for early stop\nearly_stop = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=1)","metadata":{"execution":{"iopub.status.busy":"2022-02-01T00:51:58.177707Z","iopub.execute_input":"2022-02-01T00:51:58.178153Z","iopub.status.idle":"2022-02-01T00:51:58.184101Z","shell.execute_reply.started":"2022-02-01T00:51:58.178106Z","shell.execute_reply":"2022-02-01T00:51:58.183045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit_generator(generator=train_gen, \n                              steps_per_epoch=len(train_gen), \n                              validation_data=val_gen, \n                              validation_steps=len(val_gen),\n                              epochs=1,\n                              callbacks=[checkpoint, reduce_lr, early_stop])","metadata":{"execution":{"iopub.status.busy":"2022-02-01T00:52:13.623091Z","iopub.execute_input":"2022-02-01T00:52:13.623717Z","iopub.status.idle":"2022-02-01T00:59:47.529367Z","shell.execute_reply.started":"2022-02-01T00:52:13.623355Z","shell.execute_reply":"2022-02-01T00:59:47.528384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (6,6)\n\nacc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(acc) + 1)\n\nplt.title('Training and validation accuracy')\nplt.plot(epochs, acc, 'red', label='Training acc')\nplt.plot(epochs, val_acc, 'blue', label='Validation acc')\nplt.legend()\n\nplt.figure()\nplt.title('Training and validation loss')\nplt.plot(epochs, loss, 'red', label='Training loss')\nplt.plot(epochs, val_loss, 'blue', label='Validation loss')\n\nplt.legend()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-01T01:00:08.561514Z","iopub.execute_input":"2022-02-01T01:00:08.561867Z","iopub.status.idle":"2022-02-01T01:00:09.133681Z","shell.execute_reply.started":"2022-02-01T01:00:08.56179Z","shell.execute_reply":"2022-02-01T01:00:09.132698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(max(val_acc))","metadata":{"execution":{"iopub.status.busy":"2022-02-01T01:00:12.096438Z","iopub.execute_input":"2022-02-01T01:00:12.096978Z","iopub.status.idle":"2022-02-01T01:00:12.101678Z","shell.execute_reply.started":"2022-02-01T01:00:12.096914Z","shell.execute_reply":"2022-02-01T01:00:12.100436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# predict new images","metadata":{}},{"cell_type":"markdown","source":"download some dog images from pixabay for testing","metadata":{}},{"cell_type":"code","source":"def download_before_predict(url, filename):\n    # download and save\n    os.system(\"curl -s {} -o {}\".format(url, filename))\n    img = Image.open(filename, \"w\")\n    img = img.convert('RGB')\n    img = img.resize((224, 224))\n    img.save(filename)\n    \ndef predict(url, filename):\n    \n    # show image\n    plt.figure(figsize=(4, 4))\n    plt.imshow(img)\n    plt.axis('off')\n    # predict\n    img = imread(filename)\n    img = preprocess_input(img)\n    probs = model.predict(np.expand_dims(img, axis=0))\n    for idx in probs.argsort()[0][::-1][:5]:\n        print(\"{:.2f}%\".format(probs[0][idx]*100), \"\\t\", label_maps_rev[idx].split(\"-\")[-1])","metadata":{"execution":{"iopub.status.busy":"2022-02-01T01:21:13.938318Z","iopub.execute_input":"2022-02-01T01:21:13.93861Z","iopub.status.idle":"2022-02-01T01:21:13.946108Z","shell.execute_reply.started":"2022-02-01T01:21:13.938571Z","shell.execute_reply":"2022-02-01T01:21:13.944891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# a = open(\"one.jpg\", \"w\")\na.close()","metadata":{"execution":{"iopub.status.busy":"2022-02-01T01:12:44.542024Z","iopub.execute_input":"2022-02-01T01:12:44.54232Z","iopub.status.idle":"2022-02-01T01:12:44.547167Z","shell.execute_reply.started":"2022-02-01T01:12:44.542283Z","shell.execute_reply":"2022-02-01T01:12:44.546067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"download_before_predict(\"https://cdn.pixabay.com/photo/2018/08/12/02/52/belgian-mallinois-3599991_1280.jpg\", \"two.jpg\")","metadata":{"execution":{"iopub.status.busy":"2022-02-01T01:21:15.446452Z","iopub.execute_input":"2022-02-01T01:21:15.447162Z","iopub.status.idle":"2022-02-01T01:21:36.109181Z","shell.execute_reply.started":"2022-02-01T01:21:15.446823Z","shell.execute_reply":"2022-02-01T01:21:36.107749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict(\"https://cdn.pixabay.com/photo/2018/08/12/02/52/belgian-mallinois-3599991_1280.jpg\", \"two.jpg\")","metadata":{"execution":{"iopub.status.busy":"2022-02-01T01:17:05.60447Z","iopub.execute_input":"2022-02-01T01:17:05.605083Z","iopub.status.idle":"2022-02-01T01:17:05.646988Z","shell.execute_reply.started":"2022-02-01T01:17:05.605004Z","shell.execute_reply":"2022-02-01T01:17:05.645345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"download_and_predict(\"https://cdn.pixabay.com/photo/2016/07/25/00/06/corgi-1539598_1280.jpg\",\n                     \"test_2.jpg\")","metadata":{"execution":{"iopub.status.busy":"2022-02-01T01:01:18.232617Z","iopub.execute_input":"2022-02-01T01:01:18.23298Z","iopub.status.idle":"2022-02-01T01:01:38.877663Z","shell.execute_reply.started":"2022-02-01T01:01:18.232928Z","shell.execute_reply":"2022-02-01T01:01:38.87597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"download_and_predict(\"https://cdn.pixabay.com/photo/2019/02/24/20/15/chihuahua-4018429_1280.jpg\",\n                     \"test_3.jpg\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"download_and_predict(\"https://cdn.pixabay.com/photo/2018/03/31/06/31/dog-3277416_1280.jpg\",\n                     \"test_4.jpg\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"download_and_predict(\"https://cdn.pixabay.com/photo/2016/02/19/15/46/dog-1210559_1280.jpg\",\n                     \"test_5.jpg\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# cleaning","metadata":{}},{"cell_type":"code","source":"!rm -rf data/* ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!rm -f test_*.jpg","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}